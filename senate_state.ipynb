{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import collections\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "senate=pd.read_csv(\"https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/PEJ5QU/XXQCIK\", delimiter='\\t')\n",
    "fec=pd.read_csv(\"FEC_Datasets/senate_candidates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This method removes the decimal from the FIPS code and appends the prefix of county 05000US with padding of XXAAA.\n",
    "def fips_code(x):\n",
    "    l=[]\n",
    "    for i in x:\n",
    "        if i == None:\n",
    "            l.append(str(i))\n",
    "        elif math.isnan(i):\n",
    "            l.append(str(i))\n",
    "        elif i < 10:\n",
    "            i = str(int(i))\n",
    "            l.append(\"04000US0\"+i)\n",
    "        else:\n",
    "            i = str(int(i))\n",
    "            l.append(\"04000US\"+i)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace all state_fips codes with the full fips code\n",
    "senate['state_fips'] = fips_code(senate['state_fips'])\n",
    "\n",
    "#Drop extra columns\n",
    "senate=senate.drop(['version','state_cen','state_ic','mode'], axis=1)\n",
    "\n",
    "#Sets all null candidates and Parties to Other\n",
    "senate.loc[(senate['candidate'].isnull()), 'candidate']='Other'\n",
    "senate.loc[(senate['party'].isnull()), 'party']='Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits FEC dataset by candidate election year\n",
    "def eyear(nd):\n",
    "    l=[]\n",
    "    for index,row in nd.iterrows():\n",
    "        i=row.values\n",
    "        t=i[3]\n",
    "        j=t.strip('{').strip('}').split(',')\n",
    "        for x in j:\n",
    "            l.append([i[0],i[1],i[2],int(x),i[4]])\n",
    "    return l\n",
    "\n",
    "#Remove excess from FEC dataset\n",
    "fec.drop(['office','office_full','cycles','party','candidate_status','incumbent_challenge_full','active_through', 'district', 'district_number', 'election_districts', 'incumbent_challenge', 'first_file_date', 'last_file_date','candidate_inactive','last_f2_date','load_date','inactive_election_years'], axis=1, inplace=True)\n",
    "\n",
    "#Format FEC for fuzzy matching\n",
    "fec1=pd.DataFrame(eyear(fec))\n",
    "fec1.columns=[\"name\",\"party_full\",\"state\",\"year\",\"candidate_id\"]\n",
    "fec1=fec1[(fec1[\"year\"]>=1976)&(fec1[\"year\"]<=2018)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merges all insignificant candidates for my pleasure... (Done by the percentage of votes recieved and name matching)\n",
    "#C is the list of candidates\n",
    "#df is the main dataframe\n",
    "def merge_insig(d, df):\n",
    "    keep=[]\n",
    "    other=[]\n",
    "    for candidate in d.keys():\n",
    "        if(d[candidate]==''):\n",
    "            kept=False\n",
    "            if candidate == 'other':\n",
    "                other.append(candidate)\n",
    "            else:\n",
    "                location= df.loc[(df['candidate'].str.lower().replace(\",\",'')==candidate)]\n",
    "                byyear = location.groupby('year')\n",
    "                cvote = byyear.sum()['candidatevotes']\n",
    "                tvote = byyear.sum()['totalvotes']\n",
    "                for year in cvote.index:\n",
    "                    percentage = cvote[year]/tvote[year]*100\n",
    "                    if percentage > 5:\n",
    "                        keep.append(candidate)\n",
    "                        kept=True\n",
    "                        break\n",
    "            if kept==False:\n",
    "                other.append(candidate)\n",
    "                df.loc[(df['candidate'].str.lower()==candidate), 'candidate']='Other'\n",
    "    return (keep, other)\n",
    "\n",
    "#Remove extra punctuation from the candidate name and reverse the order of names\n",
    "def modify(x):\n",
    "    sl=x.replace('\"','').split(',')\n",
    "    sl.reverse()\n",
    "    s=\"\"\n",
    "    for i in sl:\n",
    "        s=s+i+\" \"\n",
    "    return s.strip()\n",
    "#provides subsequent string matches\n",
    "def subsequence(s1,s2,m,n):\n",
    "    b=0\n",
    "    a=0\n",
    "    while b<m and a<n:\n",
    "        if s1[b]==s2[a]:\n",
    "            b+=1\n",
    "        a+=1\n",
    "    return b==m\n",
    "\n",
    "\n",
    "#first pass on the data matching to compare for direct/subsequent string matching\n",
    "def fpass(x,y):\n",
    "    #x is a list of candidate from fec and y is a list of candidates from mit\n",
    "    #output will be dictionary\n",
    "    l=collections.defaultdict(list)\n",
    "    for i in y:   \n",
    "    #     if i not in x:\n",
    "    #         l[i].append(\"\")\n",
    "    #         continue\n",
    "        f=0\n",
    "        for j in x:\n",
    "# if i is equal to j we append it to the list of the hashmap for the name in the mit data\n",
    "            if i==j:\n",
    "                l[i].append(j)\n",
    "                break\n",
    "# if they are similar we merge all the possible outcomes and use fuzz ratio technique to find the best match out of it\n",
    "            elif subsequence(i,j,len(i),len(j)) or subsequence(j,i,len(j),len(i)):\n",
    "                l[i].append(j)\n",
    "            else:\n",
    "                f+=1\n",
    "        # if it found nowhere in the fec data we add \"\"(blank string) to the dictionary\n",
    "        if f>=len(x):\n",
    "            l[i].append(\"\")\n",
    "    return l\n",
    "\n",
    "\n",
    "#final pass using fuzzywuzzy to find best matches for non perfectly matched names\n",
    "def out(a,x):\n",
    "    # a is the dictionary of the output from the fpass\n",
    "    compare=[]\n",
    "    for key,value in a.items():\n",
    "        # check for match with at least 90% confidence. If none exists, insert null value\n",
    "        if len(value)==1:    \n",
    "            if value[0]==\"\":\n",
    "                t=process.extractOne(key,x)\n",
    "                if t[1]>=90:\n",
    "                    compare.append([key,t[0]])\n",
    "                else:\n",
    "                    compare.append([key,\"\"])\n",
    "            else:\n",
    "                compare.append([key,value[0]])\n",
    "        else:\n",
    "            s=\"\"\n",
    "            m=-1\n",
    "            # if there is already a potential match we just loook for the best from the posible match found using the previous logic\n",
    "            for i in value:\n",
    "                if fuzz.ratio(key,i)>m and fuzz.ratio(key,i)>=90:\n",
    "                    m=fuzz.ratio(key,i)\n",
    "                    s=i\n",
    "            compare.append([key,s])\n",
    "    return compare\n",
    "\n",
    "\n",
    "# creating the final dictionary\n",
    "def result(b):\n",
    "    # b is the list of all the canidate match from the prvious outputs\n",
    "    hm=collections.defaultdict(str)\n",
    "    for i in b:\n",
    "        if i[0] not in hm or hm[i[0]]==\"\":\n",
    "            hm[i[0]]=i[1]\n",
    "    return hm\n",
    "\n",
    "\n",
    "#provides a list of candidate ids that succesfully matched between MIT and FEC data\n",
    "#df is the match dataframe of [MIT Candidate | FEC candidate]\n",
    "#ids is the dictionary of {FEC name : FEC id}\n",
    "def append_ids(df, ids):\n",
    "    id_list=[]\n",
    "    for index, row in df.iterrows():\n",
    "        if row['FEC data'] == \"other\":\n",
    "            id_list.append(\"S99999999\")\n",
    "        else:\n",
    "            if len(row['FEC data'])==0:\n",
    "                id_list.append(\"S99999999\")\n",
    "            else: \n",
    "                id_list.append(ids[row['FEC data']])\n",
    "    return id_list\n",
    "\n",
    "\n",
    "#Swaps candidate names with IDs in the main df\n",
    "#c is the list of candidate names from the main df\n",
    "#match is the dictionary of names to IDs made with match_fuzzily\n",
    "def replace_name(df, match, missed):\n",
    "    id_list=[]\n",
    "    for index, row in df.iterrows():\n",
    "        candidate = row['candidate'].replace('\\\\','').replace('\"','').lower()\n",
    "        if candidate == \"other\":\n",
    "            id_list.append(\"S99999999\")\n",
    "        elif candidate in missed:\n",
    "            id_list.append(\"MISSED\")\n",
    "        else:\n",
    "            if len(row['candidate'])==0:\n",
    "                id_list.append(\"S99999999\")\n",
    "            else:\n",
    "                matchid = match[(match['MIT data']==candidate)].iloc[0]['fec_id']\n",
    "                id_list.append(matchid)\n",
    "    return id_list\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate name : id dictionary\n",
    "ids={}\n",
    "for i in fec1['name'].unique():\n",
    "    ids.update({modify(i).lower() : fec1[(fec1['name']==i)].iloc[0]['candidate_id']}) \n",
    "\n",
    "#Match fuzzily the names of candidates by year\n",
    "final_l=[]\n",
    "for year in range(1976,2020,2):\n",
    "    x=[modify(i).lower() for i in fec1.loc[(fec1[\"year\"]==year),\"name\"].unique()]\n",
    "    y=[i.replace('\\\\','').replace('\"','').lower() for i in senate.loc[(senate[\"year\"]==year),\"candidate\"].unique()]\n",
    "    z=fpass(x,y)\n",
    "    final_l=final_l+out(z,x)\n",
    "final_compare=result(final_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to a dataframe\n",
    "results=pd.DataFrame(list(final_compare.items()),columns=[\"MIT data\",\"FEC data\"])\n",
    "id_df = pd.DataFrame(list(ids.items()),columns=[\"candidate\",\"id\"])\n",
    "\n",
    "#Append a list of IDs matched to FEC names that successfully matched to MIT names\n",
    "results.loc[:, 'fec_id'] = pd.Series(append_ids(results, ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missed candidates that are more than 5% of the vote: 195\n",
      "The number of missed candidates that are less than 5% of the vote: 197\n",
      "The total number of candidates in this dataset is: 2225\n"
     ]
    }
   ],
   "source": [
    "#Create a list of the insignificant candidates that were missed and a list of the important candidates missed\n",
    "merged = merge_insig(final_compare, senate)\n",
    "missed = merged[0]\n",
    "other = merged[1]\n",
    "print(\"The number of missed candidates that are more than 5% of the vote: \" + str(len(missed)) \n",
    "      + \"\\nThe number of missed candidates that are less than 5% of the vote: \" + str(len(other))\n",
    "      + \"\\nThe total number of candidates in this dataset is: \" + str(len(final_compare)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace candidates in MIT dataset with FEC_ID\n",
    "senate['candidate'] = replace_name(senate, results, missed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to CSV\n",
    "#MIT_name : FEC_name : FEC_id\n",
    "results.to_csv(\"ExportedCSV\\Senate\\MIT_fec_senate_90%CI.csv\")\n",
    "\n",
    "#FEC_name : FEC_id\n",
    "id_df.to_csv(\"ExportedCSV\\Senate\\id_candidate.csv\")\n",
    "\n",
    "#MIT Data cleaned with candidate name replaced with FEC_id\n",
    "senate.to_csv(\"ExportedCSV\\Senate\\Senate_Master.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
